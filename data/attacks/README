README


Folder: attacks

Script: attack_autoattack.py or attack_foolbox.py
Previous script: generate_clean_data.py

Correct classified images ares saved. Used: torch.save

run = { run_1, run_2, run_3, run_4 }
dataset = { cif10, cif10vgg, cif100, imagenet, imagenet32, imagenet64, imagenet128, celebaHQ32, celebaHQ64, celebaHQ128 }
architecture = {wrn}
depth = 28
width = 10
nrclasses = { 10, 25, 50, 75, 100, 250, 1000 }  ... only for imagenet32
attack = {fgsm, bim, pgd, std, df, cw }
defense = {InputPFS, InputMFS, LayerPFS, LayerMFS, }


Structure:

attacks
    <run>
        <dataset>
            <architecture>
                <depth_width_nrclasses>
                    <attack>
                        args.txt   // the parsed arguments
                        log.txt    // logger.log, is appended; with date etc...
                        clean_data // the data itself


Example. ./data/attack/run_1/cif10/wrn_28_10_10/fgsm



Debug Info:      Accuracy:

[x] cif10,         87%
[x] cif10vgg,      82%
[x] cif100,        79%
[] cif100vgg,      Not implemented!
[x] imagenet,      77%
[] imagenet32, 
[] imagenet32 10, 
[] imagenet32 25, 
[] imagenet32 50, 
[] imagenet32 75, 
[] imagenet32 100,
[] imagenet32 250,  
[x] imagenet64,    70%
[x] imagenet128,   79% 
[x] celebaHQ32,    90%   not normalized
[x] celebaHQ64,    91%   not normalized
[x] celebaHQ128    92%   not normalized

... finished